{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Advanced Training (from scratch) - Part 1\n",
    "\n",
    "In this notebook, you will adapt your code from Jupyter Notebook 3 to train a feedforward neural network (FNN) on two different datasets: \n",
    "\n",
    "- Lincoln Home Sales: contains data of single family homes sold between January 2016 and August 2022 with the features\n",
    "    - Overall Rating of Home Condition\n",
    "    - Rating of Building Material Quality\n",
    "    - Year Remodeled\n",
    "    - Remodel Type\n",
    "    - Total Living Area\n",
    "    - Year Built\n",
    "    - Garage Capacity\n",
    "    - Bedroom Count\n",
    "    - Total Basement Area\n",
    "    - Minimally Finished Basement Area\n",
    "    - Completely Finished Basement Area\n",
    "    - Fireplace Count\n",
    "    - Number of Fixtures\n",
    "    - Pool Area\n",
    "    - Total Acres\n",
    "    - Sale Date\n",
    "    - Price\n",
    "\n",
    "- MNIST: contains handwritten digits 0-9\n",
    "\n",
    "In this notebook, Part 1, we'll focus on the Lincoln Home Sales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook 3\n",
    "\n",
    "### **Problem 1A**\n",
    "In the code cell below, copy and paste the following functions from your Jupyter Notebook 3:\n",
    "\n",
    "- loss\n",
    "- loss_grad_final_layer\n",
    "- sigmoid\n",
    "- ReLU\n",
    "- sigmoid_derivative\n",
    "- ReLU_derivative\n",
    "- model_compile\n",
    "- forward_pass\n",
    "- backpropagation\n",
    "- model_gradients\n",
    "- model_update\n",
    "- model_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 1B**\n",
    "\n",
    "Make sure your ReLU function and its derivative works for vector inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapt your code above so that the user has the option as to what metrics they want printed. Also change it so that metrics are printed out every 10 iterations instead of 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(X, Y, W2, b2, W3, b3, activation, activation_derivative, learning_rate, epochs, metrics=['loss', 'accuracy']):\n",
    "    \"\"\"\n",
    "        Add your code below\n",
    "    \"\"\"\n",
    "\n",
    "    return W2, b2, W3, b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lincoln Home Sales\n",
    "\n",
    "Let's load the Lincoln Home Sales data and split it into `X_train` and `Y_train`. Our goal is to build a model that uses the first 16 features of the data to predict the price.\n",
    "\n",
    "We're going to need to make some adjustments to your training functions. Specifically, creating a training loop that performs stochastic gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "LincolnHomeSales = np.loadtxt('LincolnHomeSales.csv', delimiter=',',skiprows=1) #skiprows=1 skips the first row which contains column headers\n",
    "\n",
    "X_train = LincolnHomeSales[:,0:-1] #selects the first two columns of the data\n",
    "Y_train = LincolnHomeSales[:,-1] #selects the last column of the data\n",
    "\n",
    "del LincolnHomeSales #deletes the variable to free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 2A**\n",
    "\n",
    "How many samples are in the Lincoln Home Sales Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 2B**\n",
    "\n",
    "Normalize the data by dividing each feature of the Lincoln Home Sales Data by the maximum of the feature so that the values of each feature are between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 3A**\n",
    "\n",
    "Mean Squared Error (MSE) and the ReLU activation function are ideal for training a model to predict a home's price. MSE is great for regression problems. ReLU is more versatile, but here it will be particularly helpful because the price of a home is a possibly large positive number.\n",
    "\n",
    "Run the code in the code cell below to use your training functions from Jupyter Notebook 3 to train a model on the Lincoln Home Sales data.\n",
    "\n",
    "Note we must leave off the accuracy metric because it doesn't make sense here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network\n",
    "num_input = 16 # number of input neurons\n",
    "num_hidden = 8 # number of hidden neurons\n",
    "num_output = 1 # number of output neurons\n",
    "activation = ReLU # possible values are sigmoid or ReLU\n",
    "activation_derivative = ReLU_derivative # possible values are sigmoid_derivative or ReLU_derivative\n",
    "learning_rate = 0.1\n",
    "\n",
    "W2, b2, W3, b3 = model_compile(num_input, num_hidden, num_output, activation, learning_rate)\n",
    "W2, b2, W3, b3 = model_train(X_train, Y_train, \n",
    "                             W2, b2, W3, b3, \n",
    "                             activation, activation_derivative, \n",
    "                             learning_rate, \n",
    "                             10, \n",
    "                             metrics=['loss']) # will take a while to run\n",
    "\n",
    "print(f'W2: {W2}, b2: {b2}, W3: {W3}, b3: {b3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 3B**\n",
    "\n",
    "Why did that take so long to run? Explain in a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 3C**\n",
    "\n",
    "Adapt your `model_train` function so that it performs stochastic gradient descent.\n",
    "\n",
    "**Note:** Be sure to partition your data into batches of size `batch_size`. One of your batches may have more samples than your other batches if your batch size does not divide the total number of samples evenly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(X, Y, W2, b2, W3, b3, activation, activation_derivative, learning_rate, batch_size=32, epochs=10, metrics=['loss', 'accuracy']): # set default values for batch_size and epochs\n",
    "    \"\"\"\n",
    "        Add your code below\n",
    "    \"\"\"\n",
    "\n",
    "    return W2, b2, W3, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your new model_train function here with various batch sizes\n",
    "\n",
    "# define the neural network\n",
    "num_input = 16 # number of input neurons\n",
    "num_hidden = 8 # number of hidden neurons\n",
    "num_output = 1 # number of output neurons\n",
    "activation = ReLU # possible values are sigmoid or ReLU\n",
    "activation_derivative = ReLU_derivative # possible values are sigmoid_derivative or ReLU_derivative\n",
    "learning_rate = 0.01\n",
    "\n",
    "W2, b2, W3, b3 = model_compile(num_input, num_hidden, num_output, activation, learning_rate)\n",
    "W2, b2, W3, b3 = model_train(X_train, Y_train, \n",
    "                             W2, b2, W3, b3, \n",
    "                             activation, activation_derivative, \n",
    "                             learning_rate, \n",
    "                             batch_size=32,\n",
    "                             epochs=100,\n",
    "                             metrics=['loss']) # will take a while to run\n",
    "\n",
    "print(f'W2: {W2}, b2: {b2}, W3: {W3}, b3: {b3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 4**\n",
    "\n",
    "Without the accuracy metric it's difficult to evaluate our model's performance. Discuss a few possible ways we could evaluate the model's performance in 3-5 sentences below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 5**\n",
    "\n",
    "Implement one of the strategies you discussed in Problem 4 and train your model to a \"satisfactory\" performance level. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
